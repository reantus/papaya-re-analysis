{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation of participants' data for the analysis of response times (first cell).\n",
    "\n",
    "*1) Reading the file with all of the trials*\\\n",
    "*2) Checking the overall accuracy of participants*\\\n",
    "*3) Defining outliers (2.5 standard deviations above or below the mean) per condition per participant*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading data from 98 participants and checking their overall accuracy.\n",
    "df_data = pd.read_csv(\n",
    "    \"path_to_your_file\"\n",
    ")\n",
    "\n",
    "list_sufficient_accuracy = []\n",
    "\n",
    "# Our df_only_sufficient_accuracy contains data of participants with the overall accuracy above or exactly 70 %.\n",
    "for participant_unique_ID, df_one_participant in df_data.groupby(\n",
    "    \"Participant_unique_ID\"\n",
    "):\n",
    "\n",
    "    accuracy = df_one_participant[\"correct_keyboard_response\"].mean()\n",
    "    if accuracy >= 0.70:\n",
    "        list_sufficient_accuracy.append(participant_unique_ID)\n",
    "\n",
    "df_only_sufficient_accuracy = df_data[\n",
    "    df_data[\"Participant_unique_ID\"].isin(list_sufficient_accuracy)\n",
    "]\n",
    "\n",
    "# Working with participants with sufficient overall accuracy, we are excluding outliers per participant per condition.\n",
    "# We only take correctly answered word trials, as we are preparing a file for the analysis of response times.\n",
    "df_all_people_without_outliers = pd.DataFrame()\n",
    "list_upper_and_lower_values = []\n",
    "\n",
    "for participant_ID, df_participant in df_only_sufficient_accuracy.groupby(\n",
    "    \"Participant_unique_ID\"\n",
    "):\n",
    "\n",
    "    df_word_correct = df_participant[\n",
    "        (df_participant[\"correct_keyboard_response\"] == 1)\n",
    "        & (df_participant[\"target_type\"] == \"word\")\n",
    "    ]\n",
    "\n",
    "    participant_boundaries = [participant_ID]\n",
    "    df_subject_without_outliers = pd.DataFrame()\n",
    "\n",
    "    # Looping through all 7 flanker conditions and excluding outliers (more than 2.5 standard deviations above or below the mean value)\n",
    "    # based on the mean and standard deviation calculated per condition per participant.\n",
    "    for flanker_condition, df_condition in df_word_correct.groupby(\"flanker_condition\"):\n",
    "\n",
    "        cond_time_mean = df_condition[\"response_time_keyboard_response\"].mean()\n",
    "        cond_time_std = df_condition[\"response_time_keyboard_response\"].std()\n",
    "\n",
    "        upper_boundary = cond_time_mean + 2.5 * cond_time_std\n",
    "        lower_boundary = cond_time_mean - 2.5 * cond_time_std\n",
    "\n",
    "        df_cond_without_outliers = df_condition[\n",
    "            ((df_condition[\"response_time_keyboard_response\"]) > (lower_boundary))\n",
    "            & ((df_condition[\"response_time_keyboard_response\"]) < (upper_boundary))\n",
    "        ]\n",
    "\n",
    "        participant_boundaries.extend(\n",
    "            [flanker_condition, upper_boundary, lower_boundary]\n",
    "        )\n",
    "\n",
    "        # This dataframe contains data without outliers of a single participant.\n",
    "        df_subject_without_outliers = pd.concat(\n",
    "            [df_cond_without_outliers, df_subject_without_outliers], ignore_index=True\n",
    "        )\n",
    "\n",
    "    # Upper and lower cut-off boundaries per participant per condition are saved into a list,\n",
    "    # as they will be applied for defining outliers for the analysis of accuracies as well.\n",
    "    list_upper_and_lower_values.append(participant_boundaries)\n",
    "\n",
    "    # This dataframe contains data without outliers for all the participants with the sufficient overall accuracy.\n",
    "    df_all_people_without_outliers = pd.concat(\n",
    "        [df_all_people_without_outliers, df_subject_without_outliers], ignore_index=True\n",
    "    )\n",
    "\n",
    "# Extracting target word from the whole stimulus.\n",
    "for i in range(len(df_all_people_without_outliers)):\n",
    "    row = df_all_people_without_outliers[\"stimulus\"][i]\n",
    "    word = row.split(\" \")[3]\n",
    "    df_all_people_without_outliers.at[i, \"target\"] = word\n",
    "\n",
    "# Saving the file with all correctly answered participants' word trials without outliers for the analyis of response times.\n",
    "df_all_people_without_outliers.to_csv(\n",
    "    \"file_with_data_without_outliers_response_times.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing a file with all of the participants' trials and their upper and lower cut-off boundaries that will be used for the analysis of accuracies.\n",
    "\n",
    "*1) Creating a dataframe with participants' upper and lower boundaries from a previously created list*\\\n",
    "*2) Merging this dataframe with a dataframe tah holds all of the trials of participants that were accurate enough.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same upper and lower cut-off boundaries per participant per condition as for the response times analysis will be applied to define outliers.\n",
    "# We are firstly creating a dataframe (from a previously created list_upper_and_lower_values) with subject numbers and upper and lower boundaries per condition.\n",
    "df_limits = pd.DataFrame()\n",
    "participants = []\n",
    "\n",
    "for participant in list_upper_and_lower_values:\n",
    "    unique_ID = participant[0]\n",
    "    conditions = participant[1:]\n",
    "\n",
    "    # Looping through the 7 flanker conditions, finding upper and lower boundaries.\n",
    "    for i in range(0, len(conditions), 3):\n",
    "        condition = conditions[i]\n",
    "        upper_value = conditions[i + 1]\n",
    "        lower_value = conditions[i + 2]\n",
    "        participants.append([unique_ID, condition, upper_value, lower_value])\n",
    "\n",
    "\n",
    "df_limits = pd.DataFrame(\n",
    "    participants,\n",
    "    columns=[\n",
    "        \"Participant_unique_ID\",\n",
    "        \"flanker_condition\",\n",
    "        \"upper_boundary\",\n",
    "        \"lower_boundary\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Creating a dataframe with all trials from participants with the sufficient overall accuracy and merging it with the newly created dataframe\n",
    "# with upper and lower boundaries per condition per participant.\n",
    "df_all_data_with_boundaries = df_only_sufficient_accuracy.merge(\n",
    "    df_limits,\n",
    "    left_on=[\"Participant_unique_ID\", \"flanker_condition\"],\n",
    "    right_on=[\"Participant_unique_ID\", \"flanker_condition\"],\n",
    "    how=\"inner\",\n",
    ")\n",
    "\n",
    "# This dataframe will be used when defining outliers for the incorrectly answered trials for the analysis of accuracies (the next Jupyter Notebook file).\n",
    "df_all_data_with_boundaries.to_csv(\"all_data_with_boundaries.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
